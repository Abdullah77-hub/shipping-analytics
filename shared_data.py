# shared_data.py - Ù…Ø¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ© Ø¨ÙŠÙ† Ø§Ù„ØµÙØ­Ø§Øª
import streamlit as st
import pandas as pd
import pickle
import os
from datetime import datetime

class SharedDataManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ© Ø¨ÙŠÙ† Ø¬Ù…ÙŠØ¹ ØµÙØ­Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
    
    def __init__(self):
        self.data_key = "shared_shipping_data"
        self.init_shared_state()
    
    def init_shared_state(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©"""
        if self.data_key not in st.session_state:
            st.session_state[self.data_key] = {
                'niceone_data': None,
                'aramex_data': None, 
                'smsa_data': None,
                'postage_data': None,
                'dhl_data': None,
                'quicksilver_data': None,
                'redbox_data': None,
                'upload_times': {},
                'data_sources': {},
                'branch_files': {},
                'last_updated': None
            }
    
    def save_company_data(self, company_name, main_data, branch_files=None, source="manual"):
        """Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø±ÙƒØ© Ù…Ø¹ÙŠÙ†Ø©"""
        company_key = f"{company_name.lower()}_data"
        
        # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        st.session_state[self.data_key][company_key] = main_data
        
        # Ø­ÙØ¸ Ù…Ù„ÙØ§Øª Ø§Ù„ÙØ±ÙˆØ¹
        if branch_files:
            st.session_state[self.data_key]['branch_files'][company_name.lower()] = branch_files
        
        # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„
        st.session_state[self.data_key]['upload_times'][company_name.lower()] = datetime.now()
        st.session_state[self.data_key]['data_sources'][company_name.lower()] = source
        st.session_state[self.data_key]['last_updated'] = datetime.now()
        
        # Ø¥Ø¸Ù‡Ø§Ø± Ø±Ø³Ø§Ù„Ø© Ù†Ø¬Ø§Ø­
        st.success(f"âœ… ØªÙ… Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª {company_name} Ø¨Ù†Ø¬Ø§Ø­! Ø³ØªØ¨Ù‚Ù‰ Ù…ØªØ§Ø­Ø© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª.")
    
    def get_company_data(self, company_name):
        """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø±ÙƒØ© Ù…Ø¹ÙŠÙ†Ø©"""
        company_key = f"{company_name.lower()}_data"
        return st.session_state[self.data_key].get(company_key, None)
    
    def get_branch_files(self, company_name):
        """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ù…Ù„ÙØ§Øª ÙØ±ÙˆØ¹ Ø´Ø±ÙƒØ© Ù…Ø¹ÙŠÙ†Ø©"""
        return st.session_state[self.data_key]['branch_files'].get(company_name.lower(), None)
    
    def get_data_info(self, company_name):
        """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…ØµØ¯Ø±ØŒ ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ù…ÙŠÙ„)"""
        company_lower = company_name.lower()
        upload_time = st.session_state[self.data_key]['upload_times'].get(company_lower, None)
        data_source = st.session_state[self.data_key]['data_sources'].get(company_lower, "ØªØ¬Ø±ÙŠØ¨ÙŠ")
        
        return {
            'upload_time': upload_time,
            'source': data_source,
            'has_data': self.has_company_data(company_name)
        }
    
    def has_company_data(self, company_name):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø´Ø±ÙƒØ© Ù…Ø¹ÙŠÙ†Ø©"""
        data = self.get_company_data(company_name)
        return data is not None and len(data) > 0
    
    def clear_company_data(self, company_name):
        """Ù…Ø³Ø­ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø±ÙƒØ© Ù…Ø¹ÙŠÙ†Ø©"""
        company_key = f"{company_name.lower()}_data"
        company_lower = company_name.lower()
        
        st.session_state[self.data_key][company_key] = None
        
        if company_lower in st.session_state[self.data_key]['branch_files']:
            del st.session_state[self.data_key]['branch_files'][company_lower]
        
        if company_lower in st.session_state[self.data_key]['upload_times']:
            del st.session_state[self.data_key]['upload_times'][company_lower]
        
        if company_lower in st.session_state[self.data_key]['data_sources']:
            del st.session_state[self.data_key]['data_sources'][company_lower]
        
        st.success(f"âœ… ØªÙ… Ù…Ø³Ø­ Ø¨ÙŠØ§Ù†Ø§Øª {company_name}")
    
    def clear_all_data(self):
        """Ù…Ø³Ø­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        st.session_state[self.data_key] = {
            'niceone_data': None,
            'aramex_data': None,
            'smsa_data': None, 
            'postage_data': None,
            'dhl_data': None,
            'quicksilver_data': None,
            'redbox_data': None,
            'upload_times': {},
            'data_sources': {},
            'branch_files': {},
            'last_updated': None
        }
        st.success("âœ… ØªÙ… Ù…Ø³Ø­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    def get_all_companies_status(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø±ÙƒØ§Øª"""
        companies = ['niceone', 'aramex', 'smsa', 'postage', 'dhl', 'quicksilver', 'redbox']
        status = {}
        
        for company in companies:
            status[company] = {
                'has_data': self.has_company_data(company),
                'data_info': self.get_data_info(company)
            }
        
        return status
    
    def display_data_status(self, company_name=None):
        """Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if company_name:
            # Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø´Ø±ÙƒØ© Ù…Ø¹ÙŠÙ†Ø©
            info = self.get_data_info(company_name)
            if info['has_data']:
                upload_time = info['upload_time'].strftime('%Y-%m-%d %H:%M:%S') if info['upload_time'] else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
                st.info(f"""
                ğŸ“Š **Ø­Ø§Ù„Ø© Ø¨ÙŠØ§Ù†Ø§Øª {company_name}:**
                - âœ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø© ÙˆÙ…Ø­ÙÙˆØ¸Ø©
                - ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ù…ÙŠÙ„: {upload_time}
                - ğŸ”— Ø§Ù„Ù…ØµØ¯Ø±: {info['source']}
                - ğŸ”„ Ù…ØªØ§Ø­Ø© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª
                """)
            else:
                st.warning(f"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© Ù„Ù€ {company_name}")
        else:
            # Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø±ÙƒØ§Øª
            all_status = self.get_all_companies_status()
            companies_with_data = [name for name, status in all_status.items() if status['has_data']]
            
            if companies_with_data:
                st.success(f"âœ… Ø§Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©: {', '.join(companies_with_data).upper()}")
            else:
                st.info("ğŸ“‹ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© Ø­Ø§Ù„ÙŠØ§Ù‹")

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ ÙˆØ§Ø­Ø¯ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª
def get_data_manager():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©"""
    return SharedDataManager()

# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³Ù‡Ù„
def save_data(company_name, data, branch_files=None, source="manual"):
    """Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø±ÙƒØ© - Ø¯Ø§Ù„Ø© Ù…Ø¨Ø³Ø·Ø©"""
    manager = get_data_manager()
    manager.save_company_data(company_name, data, branch_files, source)

def get_data(company_name):
    """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø±ÙƒØ© - Ø¯Ø§Ù„Ø© Ù…Ø¨Ø³Ø·Ø©"""
    manager = get_data_manager()
    return manager.get_company_data(company_name)

def has_data(company_name):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª - Ø¯Ø§Ù„Ø© Ù…Ø¨Ø³Ø·Ø©"""
    manager = get_data_manager()
    return manager.has_company_data(company_name)

def clear_data(company_name):
    """Ù…Ø³Ø­ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø±ÙƒØ© - Ø¯Ø§Ù„Ø© Ù…Ø¨Ø³Ø·Ø©"""
    manager = get_data_manager()
    manager.clear_company_data(company_name)

def show_data_status(company_name=None):
    """Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ø¯Ø§Ù„Ø© Ù…Ø¨Ø³Ø·Ø©"""
    manager = get_data_manager()
    manager.display_data_status(company_name)

# Ø¯Ø§Ù„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ù…Ø´ØªØ±Ùƒ
def load_and_save_data(company_name, uploaded_file, branch_files=None):
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø´ØªØ±Ùƒ"""
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file, encoding='utf-8')
        else:
            df = pd.read_excel(uploaded_file)
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        df = fix_duplicate_columns(df)
        
        # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø´ØªØ±Ùƒ
        save_data(company_name, df, branch_files, "manual")
        
        return df
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
        return None

def fix_duplicate_columns(df):
    """Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©"""
    columns = df.columns.tolist()
    new_columns = []
    column_counts = {}
    
    for col in columns:
        clean_col = str(col).strip()
        if clean_col in column_counts:
            column_counts[clean_col] += 1
            new_col_name = f"{clean_col}_{column_counts[clean_col]}"
        else:
            column_counts[clean_col] = 0
            new_col_name = clean_col
        new_columns.append(new_col_name)
    
    df.columns = new_columns
    return df