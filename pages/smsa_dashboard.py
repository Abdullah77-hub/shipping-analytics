try:
    from auth_protection import check_authentication, add_logout_button
    if not check_authentication():
        st.stop()
except ImportError:
    st.error("âŒ Ù…Ù„Ù Ø§Ù„Ø­Ù…Ø§ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
    st.stop()

#!/usr/bin/env python
# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime, timedelta
import os
import matplotlib.pyplot as plt # Needed for background_gradient


# Ø§Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="Samsa Analytics",
    page_icon="ğŸ“¦",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Initialize session state
if 'show_upload' not in st.session_state:
    st.session_state.show_upload = False
if 'show_sla_upload' not in st.session_state:
    st.session_state.show_sla_upload = False

# Ø¯ÙˆØ§Ù„ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§ØªÙØ§Ù‚ÙŠØ© SLA
def save_sla_data(df, source="manual"):
    st.session_state['sla_saved_data'] = {
        'sla_df': df,
        'save_time': datetime.now(),
        'source': source,
        'total_cities': len(df)
    }

def get_sla_data():
    return st.session_state.get('sla_saved_data', None)

def has_sla_data():
    saved_data = get_sla_data()
    return saved_data is not None and 'sla_df' in saved_data

def clear_sla_data():
    if 'sla_saved_data' in st.session_state:
        del st.session_state['sla_saved_data']

def process_sla_data(df):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙŠØ§Ù†Ø§Øª SLA Ù…Ø¹ Ù…Ø±ÙˆÙ†Ø© Ø£ÙƒØ¨Ø± ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©"""
    try:
        if df.empty:
            st.error("âŒ Ù…Ù„Ù SLA ÙØ§Ø±Øº")
            return pd.DataFrame()
        
        df.columns = df.columns.str.strip()
        
        city_col = None
        days_col = None
        
        # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ Ø¹Ù† Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© ÙˆØ§Ù„Ø£ÙŠØ§Ù…
        for col in df.columns:
            col_lower = str(col).lower().strip()
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©
            if city_col is None:
                city_keywords = ['city', 'Ù…Ø¯ÙŠÙ†Ø©', 'destination', 'Ù…Ø¯Ù†', 'cities', 'location', 'Ù…ÙˆÙ‚Ø¹']
                if any(keyword in col_lower for keyword in city_keywords):
                    city_col = col
                    continue
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙŠØ§Ù…/SLA
            if days_col is None:
                days_keywords = ['day', 'ÙŠÙˆÙ…', 'Ø£ÙŠØ§Ù…', 'sla', 'target', 'days', 'Ù‡Ø¯Ù', 'Ø§ÙŠØ§Ù…']
                if any(keyword in col_lower for keyword in days_keywords):
                    days_col = col
                    continue
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø£ÙˆÙ„ Ø¹Ù…ÙˆØ¯ÙŠÙ†
        if city_col is None or days_col is None:
            if len(df.columns) >= 2:
                city_col = df.columns[0]
                days_col = df.columns[1]
                st.info(f"ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ÙŠÙ†: '{city_col}' Ù„Ù„Ù…Ø¯Ù† Ùˆ '{days_col}' Ù„Ù„Ø£ÙŠØ§Ù…")
        
        if city_col and days_col:
            try:
                # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø¯Ù†
                cities_clean = df[city_col].astype(str).str.strip()
                cities_clean = cities_clean.replace(['nan', 'NaN', 'None', ''], np.nan)
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£ÙŠØ§Ù…
                days_clean = pd.to_numeric(df[days_col], errors='coerce')
                
                sla_clean = pd.DataFrame({
                    'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©': cities_clean,
                    'SLA_Ø£ÙŠØ§Ù…': days_clean
                })
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                sla_clean = sla_clean.dropna()
                sla_clean = sla_clean[sla_clean['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©'].str.len() > 0]
                sla_clean = sla_clean[sla_clean['SLA_Ø£ÙŠØ§Ù…'] > 0]
                
                if len(sla_clean) == 0:
                    st.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø© ÙÙŠ Ù…Ù„Ù SLA Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ")
                    return pd.DataFrame()
                
                st.success(f"âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© {len(sla_clean)} Ù…Ø¯ÙŠÙ†Ø© Ù…Ù† Ù…Ù„Ù SLA")
                
                return sla_clean
                
            except Exception as process_error:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(process_error)}")
                return pd.DataFrame()
        else:
            st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© ÙˆØ§Ù„Ø£ÙŠØ§Ù… ÙÙŠ Ù…Ù„Ù SLA")
            st.info("ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ÙŠÙ†: Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© + Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù…")
            st.info(f"Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©: {list(df.columns)}")
            return pd.DataFrame()
            
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù SLA: {str(e)}")
        return pd.DataFrame()

# Ø¯ÙˆØ§Ù„ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ù„Ù€ Samsa
def save_samsa_data(df, source="manual"):
    st.session_state['samsa_saved_data'] = {
        'main_df': df,
        'save_time': datetime.now(),
        'source': source,
        'total_rows': len(df),
        'total_columns': len(df.columns)
    }

def get_samsa_data():
    return st.session_state.get('samsa_saved_data', None)

def has_samsa_data():
    saved_data = get_samsa_data()
    return saved_data is not None and 'main_df' in saved_data

def clear_samsa_data():
    if 'samsa_saved_data' in st.session_state:
        del st.session_state['samsa_saved_data']

def update_sla_calculations(df):
    """Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ SLA Ø¨Ø¹Ø¯ Ø±ÙØ¹ Ù…Ù„Ù SLA"""
    try:
        if not has_sla_data():
            return df
        
        sla_info = get_sla_data()
        sla_df = sla_info['sla_df']
        
        if sla_df.empty:
            return df
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© SLA
        sla_mapping = dict(zip(sla_df['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©'], sla_df['SLA_Ø£ÙŠØ§Ù…']))
        
        # ØªØ·Ø¨ÙŠÙ‚ SLA Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        if 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©' in df.columns:
            df['SLA_Ø£ÙŠØ§Ù…'] = df['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'].map(sla_mapping)
        
        # Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ Ø­Ø§Ù„Ø© SLA - Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Creation date
        if 'ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡' in df.columns and 'ØªØ§Ø±ÙŠØ®_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©' in df.columns:
            # Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ Ø£ÙŠØ§Ù… Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù…Ø¹ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„ØµØ­ÙŠØ­
            df['Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] = (
                pd.to_datetime(df['ØªØ§Ø±ÙŠØ®_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'].dt.date) - 
                pd.to_datetime(df['ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡'].dt.date)
            ).dt.days
            df.loc[df['Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] < 0, 'Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] = np.nan
            
            # Ø­Ø³Ø§Ø¨ Ø­Ø§Ù„Ø© SLA
            def calculate_sla_status_safe(row):
                try:
                    if pd.isna(row.get('Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰')) or pd.isna(row.get('SLA_Ø£ÙŠØ§Ù…')):
                        return 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
                    elif row['Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] < row['SLA_Ø£ÙŠØ§Ù…']:
                        return 'Ù‚Ø¨Ù„ SLA'
                    elif row['Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] == row['SLA_Ø£ÙŠØ§Ù…']:
                        return 'ÙÙŠ SLA'
                    else:
                        return 'Ø¨Ø¹Ø¯ SLA'
                except:
                    return 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
            
            df['Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰'] = df.apply(calculate_sla_status_safe, axis=1)
            
# Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ ØªØ³Ù„ÙŠÙ… Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¶Ù…Ù† SLA
            if 'ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in df.columns and 'Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in df.columns:
                try:
                    # Ø§Ù„Ø´Ø±Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ: ØªØ³Ù„ÙŠÙ… ÙÙŠ Ù†ÙØ³ ÙŠÙˆÙ… Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
                    df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£Ø³Ø§Ø³ÙŠ'] = (
                        (df['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] == 'ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…') & 
                        (df['ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªØ³Ù„ÙŠÙ…'].dt.date == df['ØªØ§Ø±ÙŠØ®_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'].dt.date)
                    )
                    
                    # FDS Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ: Ø§Ù„ØªØ³Ù„ÙŠÙ… Ù…Ù† Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø© + Ø¶Ù…Ù† SLA
                    df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'] = (
                        df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£Ø³Ø§Ø³ÙŠ'] & 
                        df['Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰'].isin(['Ù‚Ø¨Ù„ SLA', 'ÙÙŠ SLA'])
                    )
                except:
                    df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'] = False
            else:
                df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'] = False        
        return df
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ SLA: {str(e)}")
        return df

@st.cache_data(show_spinner=False, max_entries=10)
def process_samsa_data(df):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙŠØ§Ù†Ø§Øª Samsa Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© - Ù…ÙØ­Ø³Ù‘Ù† Ù„Ù„Ù…Ù„Ù Ø§Ù„Ø­Ø§Ù„ÙŠ"""
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ§Ø±ØºØ© ØªÙ…Ø§Ù…Ø§Ù‹
    df = df.dropna(how='all')
    df = df.dropna(axis=1, how='all')
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØµÙ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„ØµØ­ÙŠØ­
    header_row = 0
    max_search = min(20, len(df))
    
    for i in range(max_search):
        row_str = ' '.join(df.iloc[i].astype(str).str.lower())
        keywords_count = sum(1 for keyword in ['awb', 'reference', 'shipper', 'consignee', 'status', 'pickup', 'delivery']
                            if keyword in row_str)
        if keywords_count >= 2:
            header_row = i
            break
    
    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
    if header_row > 0:
        df.columns = df.iloc[header_row]
        df = df.iloc[header_row + 1:].reset_index(drop=True)
    
    # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    df.columns = df.columns.astype(str).str.strip().str.replace('\n', ' ')
    
    # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© - Ù…Ø­Ø³Ù† Ù„Ù„Ù…Ù„Ù Ø§Ù„Ø­Ø§Ù„ÙŠ
    column_mapping = {}
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±Ù‚Ù… Ø§Ù„Ø´Ø­Ù†Ø©
    for col in df.columns:
        col_clean = str(col).strip()
        if any(keyword in col_clean for keyword in ['AWB', 'awb', 'Reference', 'reference', 'Tracking']):
            column_mapping[col] = 'Ø±Ù‚Ù…_Ø§Ù„Ø´Ø­Ù†Ø©'
            break
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©
    for col in df.columns:
        col_clean = str(col).strip()
        if any(keyword in col_clean for keyword in ['Consignee City', 'City', 'city']):
            column_mapping[col] = 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'
            break
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„
    for col in df.columns:
        col_clean = str(col).strip()
        if any(keyword in col_clean for keyword in ['Shipper Name', 'Shipper']):
            column_mapping[col] = 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø±Ø³Ù„'
            break
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…
    for col in df.columns:
        col_clean = str(col).strip()
        if any(keyword in col_clean for keyword in ['Consignee Name', 'Consignee']):
            column_mapping[col] = 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø³ØªÙ„Ù…'
            break
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‡Ø§ØªÙ Ø§Ù„Ù…Ø³ØªÙ„Ù…
    for col in df.columns:
        col_clean = str(col).strip()
        if any(keyword in col_clean for keyword in ['Consignee Phone', 'Phone']):
            column_mapping[col] = 'Ù‡Ø§ØªÙ_Ø§Ù„Ù…Ø³ØªÙ„Ù…'
            break
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
    for col in df.columns:
        col_clean = str(col).strip()
        if any(keyword in col_clean for keyword in ['Consignee Address', 'Address']):
            column_mapping[col] = 'Ø¹Ù†ÙˆØ§Ù†_Ø§Ù„Ù…Ø³ØªÙ„Ù…'
            break
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† COD
    for col in df.columns:
        col_clean = str(col).strip()
        if col_clean == 'COD':
            column_mapping[col] = 'Ø§Ù„Ù…Ø¨Ù„Øº_Ø§Ù„Ù…Ø³ØªØ­Ù‚'
            break
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ø·Ø¹
    for col in df.columns:
        col_clean = str(col).strip()
        if col_clean == 'PCs':
            column_mapping[col] = 'Ø¹Ø¯Ø¯_Ø§Ù„Ù‚Ø·Ø¹'
            break
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙˆØ²Ù†
    for col in df.columns:
        col_clean = str(col).strip()
        if 'Weight' in col_clean:
            column_mapping[col] = 'Ø§Ù„ÙˆØ²Ù†'
            break
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª
    for col in df.columns:
        col_clean = str(col).strip()
        if col_clean == 'Contents':
            column_mapping[col] = 'Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª'
            break
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
    for col in df.columns:
        col_clean = str(col).strip()
        if col_clean == 'Creation date':
            column_mapping[col] = 'ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡'
        elif col_clean == 'Pickup date':
            column_mapping[col] = 'ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…'
        elif col_clean == 'First attempt':
            column_mapping[col] = 'ØªØ§Ø±ÙŠØ®_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'
        elif col_clean == 'Delivery date':
            column_mapping[col] = 'ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªØ³Ù„ÙŠÙ…'
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø­Ø§Ù„Ø©
    for col in df.columns:
        col_clean = str(col).strip()
        if col_clean == 'Status':
            column_mapping[col] = 'Ø§Ù„Ø­Ø§Ù„Ø©'
            break
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø´Ø±ÙƒØ© 3PL
    for col in df.columns:
        col_clean = str(col).strip()
        if '3PL Company' in col_clean:
            column_mapping[col] = 'Ø´Ø±ÙƒØ©_3PL'
            break
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù†Ø·Ù‚Ø©
    for col in df.columns:
        col_clean = str(col).strip()
        if col_clean == 'Region':
            column_mapping[col] = 'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'
            break
    
    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    df = df.rename(columns=column_mapping)
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
    date_columns = ['ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡', 'ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…', 'ØªØ§Ø±ÙŠØ®_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©', 'ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªØ³Ù„ÙŠÙ…']
    for col in date_columns:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
    numeric_columns = ['Ø§Ù„Ù…Ø¨Ù„Øº_Ø§Ù„Ù…Ø³ØªØ­Ù‚', 'Ø¹Ø¯Ø¯_Ø§Ù„Ù‚Ø·Ø¹', 'Ø§Ù„ÙˆØ²Ù†']
    for col in numeric_columns:
        if col in df.columns:
            if pd.api.types.is_numeric_dtype(df[col]):
                df[col] = pd.to_numeric(df[col], errors='coerce')
            else:
                temp_series = df[col].astype(str).str.replace(r'[^\d.-]', '', regex=True)
                temp_series = temp_series.str.replace('Ù«', '.', regex=False)
                df[col] = pd.to_numeric(temp_series, errors='coerce')
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ SLA - ÙÙ‚Ø· Ø¥Ø°Ø§ ØªÙ… Ø±ÙØ¹ Ù…Ù„Ù SLA
    sla_df_for_processing = pd.DataFrame()
    if has_sla_data():
        sla_info = get_sla_data()
        sla_df_for_processing = sla_info['sla_df']
    
    if 'ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…' in df.columns and 'ØªØ§Ø±ÙŠØ®_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©' in df.columns:
        df['Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] = (
            pd.to_datetime(df['ØªØ§Ø±ÙŠØ®_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'].dt.date) - 
            pd.to_datetime(df['ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…'].dt.date)
        ).dt.days
        df.loc[df['Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] < 0, 'Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] = np.nan
        
        # Ø­Ø³Ø§Ø¨ Ø­Ø§Ù„Ø© SLA Ù„Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ - ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù…Ù„Ù SLA
        if not sla_df_for_processing.empty and 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©' in df.columns:
            # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© SLA
            sla_mapping = dict(zip(sla_df_for_processing['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©'], sla_df_for_processing['SLA_Ø£ÙŠØ§Ù…']))
            
            # ØªØ·Ø¨ÙŠÙ‚ SLA Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            df['SLA_Ø£ÙŠØ§Ù…'] = df['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'].map(sla_mapping)
            
            # Ø­Ø³Ø§Ø¨ Ø­Ø§Ù„Ø© SLA Ù„Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
            def calculate_sla_status(row):
                if pd.isna(row['Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰']) or pd.isna(row['SLA_Ø£ÙŠØ§Ù…']):
                    return 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
                elif row['Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] < row['SLA_Ø£ÙŠØ§Ù…']:
                    return 'Ù‚Ø¨Ù„ SLA'
                elif row['Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] == row['SLA_Ø£ÙŠØ§Ù…']:
                    return 'ÙÙŠ SLA'
                else:
                    return 'Ø¨Ø¹Ø¯ SLA'
            
            df['Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰'] = df.apply(calculate_sla_status, axis=1)
        else:
            # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ù…Ù„Ù SLAØŒ Ù„Ø§ Ù†Ø­Ø³Ø¨ Ø­Ø§Ù„Ø© SLA
            df['Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰'] = 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
            df['SLA_Ø£ÙŠØ§Ù…'] = np.nan
    
    # Ø­Ø³Ø§Ø¨ Ø£ÙŠØ§Ù… Ø§Ù„ØªÙˆØµÙŠÙ„ Ù…Ø¹ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„ØµØ­ÙŠØ­ - Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Creation date
    if 'ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡' in df.columns and 'ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in df.columns:
        df['Ø£ÙŠØ§Ù…_Ø§Ù„ØªÙˆØµÙŠÙ„'] = (
            pd.to_datetime(df['ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªØ³Ù„ÙŠÙ…'].dt.date) - 
            pd.to_datetime(df['ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡'].dt.date)
        ).dt.days
    df.loc[df['Ø£ÙŠØ§Ù…_Ø§Ù„ØªÙˆØµÙŠÙ„'] < 0, 'Ø£ÙŠØ§Ù…_Ø§Ù„ØªÙˆØµÙŠÙ„'] = np.nan
    
    # ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ³Ù„ÙŠÙ…
    if 'Ø§Ù„Ø­Ø§Ù„Ø©' in df.columns:
        status_str = df['Ø§Ù„Ø­Ø§Ù„Ø©'].astype(str).str.upper()
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ«Ù†Ø§Ø©
        df['Ù…Ø³ØªØ«Ù†Ù‰'] = status_str.str.contains('PICKED UP|PICKUP|Ø§Ù„ØªÙ‚Ø§Ø·', na=False, regex=True)
        
        # ØªØµÙ†ÙŠÙ Ø§Ù„Ø­Ø§Ù„Ø§Øª
        df['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] = np.select(
            [
                df['Ù…Ø³ØªØ«Ù†Ù‰'],
                status_str.str.contains('DELIVERED|RECEIVED|ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…|Ù…Ø³ØªÙ„Ù…|Ø§Ø³ØªÙ„Ù…|COMPLETE', na=False),
                status_str.str.contains('RETURN|Ù…Ø±ØªØ¬Ø¹|Ø±Ø¬Ø¹|Ø§Ø±Ø¬Ø§Ø¹|REJECT|REFUSED|FAIL', na=False)
            ],
            ['Ù…Ø³ØªØ«Ù†Ù‰', 'ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…', 'Ù…Ø±ØªØ¬Ø¹'],
            default='Ù‚ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠÙ„'
        )
    else:
        df['Ù…Ø³ØªØ«Ù†Ù‰'] = False
        if 'ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in df.columns:
            df['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] = df['ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªØ³Ù„ÙŠÙ…'].apply(
                lambda x: 'ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…' if pd.notna(x) else 'Ù‚ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠÙ„'
            )
        else:
            df['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] = 'Ù‚ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠÙ„'
    
    # Ø¥Ø¶Ø§ÙØ© Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ - Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Creation date
    if 'ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡' in df.columns:
        df['Ø±Ù‚Ù…_Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹'] = df['ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡'].dt.isocalendar().week
        df['Ø§Ù„Ø´Ù‡Ø±'] = df['ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡'].dt.month
        df['Ø§Ù„Ø³Ù†Ø©'] = df['ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡'].dt.year 
    # ØªØ­Ø¯ÙŠØ¯ FDS (First Delivery Success) Ù…Ø¹ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® ÙÙ‚Ø·
    if 'ØªØ§Ø±ÙŠØ®_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©' in df.columns and 'ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in df.columns:
        try:
            # Ø§Ù„Ø´Ø±Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ: ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ… ÙÙŠ Ù†ÙØ³ ÙŠÙˆÙ… Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
            df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£Ø³Ø§Ø³ÙŠ'] = (
                (df['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] == 'ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…') & 
                (df['ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªØ³Ù„ÙŠÙ…'].dt.date == df['ØªØ§Ø±ÙŠØ®_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'].dt.date)
            )
            
            # FDS Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ: Ø§Ù„ØªØ³Ù„ÙŠÙ… Ù…Ù† Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø© + Ø¶Ù…Ù† SLA
            if not sla_df_for_processing.empty and 'Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰' in df.columns:
                df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'] = (
                    df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£Ø³Ø§Ø³ÙŠ'] & 
                    df['Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰'].isin(['Ù‚Ø¨Ù„ SLA', 'ÙÙŠ SLA'])
                )
            else:
                # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ SLAØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø´Ø±Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙÙ‚Ø·
                df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'] = df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£Ø³Ø§Ø³ÙŠ']
        except:
            df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'] = False
    else:
        df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'] = False

    # Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ù…Ù† Ø§Ù„Ø¹Ù†ÙˆØ§Ù† (Ø£Ø³Ø§Ø³ÙŠ)
    if 'Ø¹Ù†ÙˆØ§Ù†_Ø§Ù„Ù…Ø³ØªÙ„Ù…' in df.columns:
        df['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'] = df['Ø¹Ù†ÙˆØ§Ù†_Ø§Ù„Ù…Ø³ØªÙ„Ù…'].astype(str).str.extract(r'(\w+\s*\w*)', expand=False).fillna('ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
    elif 'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©' not in df.columns:
        df['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'] = 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø±Ù‚Ù… Ø§Ù„Ø´Ø­Ù†Ø©
    if 'Ø±Ù‚Ù…_Ø§Ù„Ø´Ø­Ù†Ø©' not in df.columns:
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ø¹Ù…ÙˆØ¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø´Ø­Ù†Ø§Øª ÙØ±ÙŠØ¯Ø©
        found_awb_column = False
        for col in df.columns:
            col_str = str(col).lower()
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ø±Ù‚Ù… Ø§Ù„Ø´Ø­Ù†Ø©
            if any(keyword in col_str for keyword in ['awb', 'tracking', 'shipment', 'waybill', 'reference', 'number']):
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… ÙØ±ÙŠØ¯Ø© ÙˆÙ…Ø¹Ù‚ÙˆÙ„Ø©
                unique_ratio = df[col].nunique() / len(df)
                if unique_ratio > 0.8:  # 80% Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… ÙØ±ÙŠØ¯Ø©
                    df['Ø±Ù‚Ù…_Ø§Ù„Ø´Ø­Ù†Ø©'] = df[col].astype(str).str.strip()
                    found_awb_column = True
                    break
        
        if not found_awb_column:
            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø¹Ù…ÙˆØ¯ Ù…Ù†Ø§Ø³Ø¨ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙÙ‡Ø±Ø³ Ù…Ø¹ ØªØ­Ø°ÙŠØ±
            df['Ø±Ù‚Ù…_Ø§Ù„Ø´Ø­Ù†Ø©'] = df.index.astype(str)
    
    return df

@st.cache_data(show_spinner=False)
def calculate_performance_metrics(df):
    """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© - ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ SLA"""
    try:
        if 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©' not in df.columns:
            return pd.DataFrame()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù SLA
        if not has_sla_data():
            return pd.DataFrame()
        
        # Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ«Ù†Ø§Ø©
        df_active = df[~df.get('Ù…Ø³ØªØ«Ù†Ù‰', False)]
        
        if len(df_active) == 0:
            return pd.DataFrame()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¹Ù…ÙˆØ¯ SLA ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if 'SLA_Ø£ÙŠØ§Ù…' not in df_active.columns:
            return pd.DataFrame()
        
        metrics_list = []
        
        for city in df_active['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'].unique():
            if pd.isna(city):
                continue
                
            city_df = df_active[df_active['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'] == city]
            
            # ÙÙ„ØªØ±Ø© Ø§Ù„Ù…Ø¯Ù† Ø§Ù„ØªÙŠ Ù„Ù‡Ø§ SLA Ù…Ø­Ø¯Ø¯ ÙÙ‚Ø·
            city_df_with_sla = city_df[city_df['SLA_Ø£ÙŠØ§Ù…'].notna()]
            
            if len(city_df_with_sla) == 0:
                continue
                
            total_shipments = len(city_df_with_sla)
            
            # Ø­Ø³Ø§Ø¨ SLA Ù†Ø³Ø¨Ø© (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª ÙÙŠ Ø£Ùˆ Ù‚Ø¨Ù„ SLA)
            sla_compliant = 0
            if 'Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰' in city_df_with_sla.columns:
                sla_compliant = len(city_df_with_sla[
                    city_df_with_sla['Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰'].isin(['Ù‚Ø¨Ù„ SLA', 'ÙÙŠ SLA'])
                ])
            sla_rate = (sla_compliant / total_shipments * 100) if total_shipments > 0 else 0
            
            # Ø­Ø³Ø§Ø¨ DR (Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ³Ù„ÙŠÙ…)
            delivered_count = len(city_df_with_sla[city_df_with_sla.get('Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…', '') == 'ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…'])
            dr = (delivered_count / total_shipments * 100) if total_shipments > 0 else 0
            
            # Ø­Ø³Ø§Ø¨ FDS (Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ³Ù„ÙŠÙ… Ù…Ù† Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©)
            # Ø­Ø³Ø§Ø¨ FDS (Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ³Ù„ÙŠÙ… Ù…Ù† Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¶Ù…Ù† SLA)
            fds_count = 0
            if 'ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©' in city_df_with_sla.columns:
                # FDS = Ø§Ù„ØªØ³Ù„ÙŠÙ… Ù…Ù† Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø© + Ø¶Ù…Ù† SLA Ù…Ù† Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©
                fds_count = len(city_df_with_sla[city_df_with_sla['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'] == True])
            fds = (fds_count / total_shipments * 100) if total_shipments > 0 else 0
            # Ø­Ø³Ø§Ø¨ Pending (Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©)
            pending_count = len(city_df_with_sla[city_df_with_sla.get('Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…', '') == 'Ù‚ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠÙ„'])
            pending_rate = (pending_count / total_shipments * 100) if total_shipments > 0 else 0
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©
            region = city_df_with_sla['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'].iloc[0] if 'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©' in city_df_with_sla.columns and len(city_df_with_sla) > 0 else 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
            
            # Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹
            week_number = 0
            if 'Ø±Ù‚Ù…_Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹' in city_df_with_sla.columns:
                week_mode = city_df_with_sla['Ø±Ù‚Ù…_Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹'].mode()
                if len(week_mode) > 0:
                    week_number = int(week_mode.iloc[0])
            
            # SLA Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©
            city_sla = city_df_with_sla['SLA_Ø£ÙŠØ§Ù…'].iloc[0]
            if pd.isna(city_sla):
                continue
            
            metrics_list.append({
                'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©': city,
                'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©': region,
                'Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª': total_shipments,
                'SLA_Ø§Ù„Ù…Ø­Ø¯Ø¯': int(city_sla),
                'SLA_Ù†Ø³Ø¨Ø©': round(sla_rate, 1),
                'DR': round(dr, 1),
                'FDS': round(fds, 1),
                'Pending': round(pending_rate, 1),
                'Ø±Ù‚Ù…_Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹': week_number
            })
        
        return pd.DataFrame(metrics_list).sort_values('Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª', ascending=False)
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡: {str(e)}")
        return pd.DataFrame()

@st.cache_data(show_spinner=False)
def calculate_weekly_metrics(df):
    """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø­Ø³Ø¨ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"""
    if 'Ø±Ù‚Ù…_Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹' not in df.columns:
        return pd.DataFrame()
    
    # Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ«Ù†Ø§Ø©
    df_active = df[~df.get('Ù…Ø³ØªØ«Ù†Ù‰', False)]
    
    if len(df_active) == 0:
        return pd.DataFrame()
    
    weekly_metrics = []
    
    for week in sorted(df_active['Ø±Ù‚Ù…_Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹'].dropna().unique()):
        week_df = df_active[df_active['Ø±Ù‚Ù…_Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹'] == week]
        total_shipments = len(week_df)
        
        if total_shipments == 0:
            continue
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ù„Ù„Ø£Ø³Ø¨ÙˆØ¹
        sla_compliant = 0
        if 'Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰' in week_df.columns:
            sla_compliant = len(week_df[
                week_df['Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰'].isin(['Ù‚Ø¨Ù„ SLA', 'ÙÙŠ SLA'])
            ])
        sla_rate = (sla_compliant / total_shipments * 100) if total_shipments > 0 else 0
        
        delivered_count = len(week_df[week_df['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] == 'ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…'])
        dr = (delivered_count / total_shipments * 100) if total_shipments > 0 else 0
        
        fds_count = 0
        if 'ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©' in week_df.columns:
            fds_count = len(week_df[week_df['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'] == True])
        fds = (fds_count / total_shipments * 100) if total_shipments > 0 else 0
        
        pending_count = len(week_df[week_df['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] == 'Ù‚ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠÙ„'])
        pending_rate = (pending_count / total_shipments * 100) if total_shipments > 0 else 0
        
        weekly_metrics.append({
            'Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹': int(week),
            'Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª': total_shipments,
            'SLA_Ù†Ø³Ø¨Ø©': round(sla_rate, 1),
            'DR': round(dr, 1),
            'FDS': round(fds, 1),
            'Pending': round(pending_rate, 1)
        })
    
    return pd.DataFrame(weekly_metrics)

@st.cache_data(show_spinner=False)
def analyze_delivery_performance_fast(df):
    """ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªÙˆØµÙŠÙ„ Ù„Ù€ Samsa"""
    analysis = {}
    
    # Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ«Ù†Ø§Ø© Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„
    df_active = df[~df.get('Ù…Ø³ØªØ«Ù†Ù‰', False)]
    
    if 'Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in df_active.columns:
        # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„ØªØ³Ù„ÙŠÙ…
        total = len(df_active)
        status_counts = df_active['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'].value_counts()
        
        analysis['Ù…Ø¹Ø¯Ù„Ø§Øª_Ø§Ù„Ø­Ø§Ù„Ø©'] = {}
        for status in ['ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…', 'Ù‚ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠÙ„', 'Ù…Ø±ØªØ¬Ø¹']:
            count = status_counts.get(status, 0)
            analysis['Ù…Ø¹Ø¯Ù„Ø§Øª_Ø§Ù„Ø­Ø§Ù„Ø©'][status] = {
                'Ø§Ù„Ø¹Ø¯Ø¯': count,
                'Ø§Ù„Ù†Ø³Ø¨Ø©': round(count/total*100, 1) if total > 0 else 0
            }
    
    return analysis

@st.cache_data(show_spinner=False)
def analyze_cities_performance_samsa(df, city_filter=None, country_filter=None):
    """ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ù† Ù„Ù€ Samsa"""
    if 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©' not in df.columns:
        return pd.DataFrame()
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„Ø§ØªØ±
    df_filtered = df.copy()
    
    # Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ«Ù†Ø§Ø©
    df_filtered = df_filtered[~df_filtered.get('Ù…Ø³ØªØ«Ù†Ù‰', False)]
    
    if city_filter and city_filter != 'Ø§Ù„ÙƒÙ„':
        df_filtered = df_filtered[df_filtered['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'] == city_filter]
    if country_filter and country_filter != 'Ø§Ù„ÙƒÙ„' and 'Ø§Ù„Ø¯ÙˆÙ„Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©' in df.columns:
        df_filtered = df_filtered[df_filtered['Ø§Ù„Ø¯ÙˆÙ„Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'] == country_filter]
    
    if len(df_filtered) == 0:
        return pd.DataFrame()
    
    agg_dict = {'Ø±Ù‚Ù…_Ø§Ù„Ø´Ø­Ù†Ø©': 'count'}
    
    if 'Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in df_filtered.columns:
        df_filtered['ØªÙ…_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] = (df_filtered['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] == 'ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…').astype(int)
        agg_dict['ØªÙ…_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] = 'sum'
    
    if 'Ø£ÙŠØ§Ù…_Ø§Ù„ØªÙˆØµÙŠÙ„' in df_filtered.columns and 'Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in df_filtered.columns:
        # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø£ÙŠØ§Ù… Ø§Ù„ØªÙˆØµÙŠÙ„ Ù„Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù…Ø³Ù„Ù…Ø© ÙÙ‚Ø·
        delivered_mask = df_filtered['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] == 'ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…'
        df_filtered['Ø£ÙŠØ§Ù…_Ø§Ù„ØªÙˆØµÙŠÙ„_Ù…Ø³Ù„Ù…'] = df_filtered['Ø£ÙŠØ§Ù…_Ø§Ù„ØªÙˆØµÙŠÙ„'].where(delivered_mask)
        agg_dict['Ø£ÙŠØ§Ù…_Ø§Ù„ØªÙˆØµÙŠÙ„_Ù…Ø³Ù„Ù…'] = lambda x: x.dropna().mean()
    
    if 'Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰' in df_filtered.columns:
        agg_dict['Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] = lambda x: x.dropna().mean()
    
    # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©
    city_analysis = df_filtered.groupby('Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©', observed=True).agg(agg_dict)
    
    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    rename_dict = {'Ø±Ù‚Ù…_Ø§Ù„Ø´Ø­Ù†Ø©': 'Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª'}
    if 'ØªÙ…_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in agg_dict:
        rename_dict['ØªÙ…_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] = 'Ø§Ù„Ù…Ø³Ù„Ù…'
    if 'Ø£ÙŠØ§Ù…_Ø§Ù„ØªÙˆØµÙŠÙ„_Ù…Ø³Ù„Ù…' in city_analysis.columns:
        rename_dict['Ø£ÙŠØ§Ù…_Ø§Ù„ØªÙˆØµÙŠÙ„_Ù…Ø³Ù„Ù…'] = 'Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ù„Ù„ØªÙˆØµÙŠÙ„'
    if 'Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰' in city_analysis.columns:
        rename_dict['Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] = 'Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'
    
    city_analysis = city_analysis.rename(columns=rename_dict)
    
    # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ³Ù„ÙŠÙ…
    if 'Ø§Ù„Ù…Ø³Ù„Ù…' in city_analysis.columns:
        city_analysis['Ù†Ø³Ø¨Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] = (city_analysis['Ø§Ù„Ù…Ø³Ù„Ù…'] / city_analysis['Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª'] * 100).round(1)
    
    # ØªÙ‚Ø±ÙŠØ¨ Ø§Ù„Ù‚ÙŠÙ…
    for col in ['Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ù„Ù„ØªÙˆØµÙŠÙ„', 'Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰']:
        if col in city_analysis.columns:
            city_analysis[col] = city_analysis[col].round(1)
    
    return city_analysis.sort_values('Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª', ascending=False)

# CSS Ù…Ø®ØµØµ Ù„Ù€ Samsa
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@300;400;600;700&display=swap');
    
    * {
        font-family: 'Cairo', sans-serif !important;
    }
    
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
    }
    
    .samsa-header {
        background: linear-gradient(135deg, #5f27cd, #341f97);
        padding: 1.5rem;
        border-radius: 15px;
        margin-bottom: 1rem;
        text-align: center;
        box-shadow: 0 4px 20px rgba(0,0,0,0.1);
    }
    
    .samsa-title {
        color: white;
        font-size: 2.5rem;
        font-weight: 700;
        margin: 0;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    
    .samsa-subtitle {
        color: #fff;
        font-size: 1rem;
        margin-top: 0.3rem;
        opacity: 0.9;
    }
    
    .upload-area {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #5f27cd;
    }
    
    .kpi-container {
        display: flex;
        gap: 1rem;
        margin-bottom: 1.5rem;
        flex-wrap: wrap;
    }
    
    .kpi-card {
        flex: 1;
        min-width: 200px;
        background: white;
        padding: 1.5rem 1rem;
        border-radius: 12px;
        box-shadow: 0 2px 10px rgba(95, 39, 205, 0.15);
        text-align: center;
        border-left: 4px solid;
        transition: transform 0.2s ease;
    }
    
    .kpi-card:hover {
        transform: translateY(-3px);
    }
    
    .kpi-card.shipments { border-left-color: #5f27cd; }
    .kpi-card.delivered { border-left-color: #00d2d3; }
    .kpi-card.transit { border-left-color: #ff9ff3; }
    .kpi-card.cities { border-left-color: #feca57; }
    .kpi-card.excluded { border-left-color: #e74c3c; }
    
    .kpi-value {
        font-size: 2rem;
        font-weight: 700;
        margin: 0;
        color: #2c3e50;
    }
    
    .kpi-label {
        font-size: 0.9rem;
        color: #7f8c8d;
        margin-top: 0.3rem;
        font-weight: 600;
    }
    
    .kpi-delta {
        font-size: 0.8rem;
        margin-top: 0.2rem;
        padding: 0.1rem 0.5rem;
        border-radius: 15px;
        display: inline-block;
    }
    
    .chart-container {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 2px 10px rgba(95, 39, 205, 0.1);
        margin-bottom: 1.5rem;
        border-top: 3px solid #5f27cd;
    }
    
    .chart-title {
        color: #2c3e50;
        font-size: 1.2rem;
        font-weight: 700;
        margin-bottom: 1rem;
        text-align: center;
        border-bottom: 1px solid #5f27cd;
        padding-bottom: 0.3rem;
    }
    
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stDeployButton {display: none;}
    
    .block-container {
        max-width: 1400px;
        padding-top: 1rem;
    }
    
    .dataframe {
        font-size: 0.9rem !important;
    }
    
    .stSpinner > div {
        border-color: #5f27cd !important;
    }
</style>
""", unsafe_allow_html=True)

# Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
st.markdown("""
<div class="samsa-header">
    <div class="samsa-title">Samsa Analytics</div>
    <div class="samsa-subtitle">ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø­Ù†Ø§Øª Ø³Ù…Ø³Ø§ - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø°ÙƒÙŠØ© ÙˆØ³Ø±ÙŠØ¹Ø© - Ù…ÙØµØ­Ø­ Ù„Ù„Ù…Ù„Ù Ø§Ù„Ø­Ø§Ù„ÙŠ</div>
</div>
""", unsafe_allow_html=True)

# Ø´Ø±ÙŠØ· Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ù…Ø¯Ù…Ø¬
col1, col2, col3, col4, col5 = st.columns([2, 2, 2, 1, 1])

with col1:
    if st.button("ğŸ“¤ Ø±ÙØ¹ Samsa", use_container_width=True, type="primary"):
        st.session_state.show_upload = not st.session_state.show_upload
        st.session_state.show_sla_upload = False

with col2:
    if st.button("ğŸ“‹ Ø±ÙØ¹ SLA", use_container_width=True):
        st.session_state.show_sla_upload = not st.session_state.show_sla_upload
        st.session_state.show_upload = False

with col3:
    if st.button("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨", use_container_width=True, help="Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ SLA Ø¨Ø¹Ø¯ Ø±ÙØ¹ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯"):
        if has_samsa_data() and has_sla_data():
            with st.spinner("Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª..."):
                saved_data = get_samsa_data()
                df_updated = update_sla_calculations(saved_data['main_df'])
                save_samsa_data(df_updated, "Ù…Ø­Ø¯Ø«_Ù…Ø¹_SLA")
                st.success("âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª!")
                st.rerun()
        else:
            st.warning("ÙŠØ¬Ø¨ Ø±ÙØ¹ Ù…Ù„Ù Samsa Ùˆ SLA Ø£ÙˆÙ„Ø§Ù‹")

with col4:
    if has_samsa_data() and st.button("ğŸ—‘ï¸", use_container_width=True, help="Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
        clear_samsa_data()
        if has_sla_data():
            clear_sla_data()
        st.rerun()

with col5:
    # Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if has_samsa_data():
        saved_info = get_samsa_data()
        st.markdown(f"<p style='color: #28a745; text-align: center; font-size: 1.1rem; font-weight: bold;'>âœ“ {saved_info['total_rows']:,}</p>", unsafe_allow_html=True)
    else:
        st.markdown(f"<p style='color: #17a2b8; text-align: center; font-size: 1.1rem; font-weight: bold;'>ğŸ“Š</p>", unsafe_allow_html=True)

# Ù…Ù†Ø·Ù‚Ø© Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
if st.session_state.show_upload:
    st.markdown('<div class="upload-area">', unsafe_allow_html=True)
    uploaded_file = st.file_uploader(
        "Ø§Ø®ØªØ± Ù…Ù„Ù Samsa Excel",
        type=['xlsx', 'xls', 'csv'],
        key="samsa_uploader",
        help="ÙŠØ¯Ø¹Ù… Ù…Ù„ÙØ§Øª Excel Ùˆ CSV Ù…Ø¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"
    )
    
    # Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    with st.expander("ğŸ“‹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", expanded=False):
        st.markdown("""
        **Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:**
        - `AWB` Ø£Ùˆ `Reference` - Ø±Ù‚Ù… Ø§Ù„Ø´Ø­Ù†Ø© (Ù…Ø·Ù„ÙˆØ¨)
        - `Shipper Name` - Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„
        - `Consignee Name` - Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…  
        - `Consignee Phone` - Ù‡Ø§ØªÙ Ø§Ù„Ù…Ø³ØªÙ„Ù…
        - `Consignee City` - Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø³ØªÙ„Ù… (Ù…Ø·Ù„ÙˆØ¨ Ù„Ù„Ù€ SLA)
        - `Consignee Address` - Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ø³ØªÙ„Ù…
        - `COD` - Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„Ù…Ø³ØªØ­Ù‚
        - `PCs` - Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ø·Ø¹
        - `Weight(KG)` - Ø§Ù„ÙˆØ²Ù†
        - `Contents` - Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª
        - `Creation date` - ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡
        - `Pickup date` - ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù… (Ù…Ø·Ù„ÙˆØ¨)
        - `First attempt` - ØªØ§Ø±ÙŠØ® Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø© (Ù…Ø·Ù„ÙˆØ¨ Ù„Ù„Ù€ SLA)
        - `Delivery date` - ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ³Ù„ÙŠÙ…
        - `Status` - Ø§Ù„Ø­Ø§Ù„Ø© (Ù…Ø·Ù„ÙˆØ¨)
        
        âš ï¸ **Ù…Ù‡Ù…:** ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ø·Ø§Ø¨Ù‚Ø© ØªÙ…Ø§Ù…Ø§Ù‹ Ù„Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© Ø£Ø¹Ù„Ø§Ù‡
        """)
    
    if uploaded_file:
        try:
            with st.spinner("Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
                # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                else:
                    try:
                        excel_file = pd.ExcelFile(uploaded_file)
                        target_sheet = None
                        for sheet in excel_file.sheet_names:
                            sheet_lower = sheet.lower()
                            if any(keyword in sheet_lower for keyword in 
                                   ['data', 'detail', 'Ø¨ÙŠØ§Ù†Ø§Øª', 'ØªÙØ§ØµÙŠÙ„', 'shipment', 'Ø´Ø­Ù†Ø§Øª']):
                                target_sheet = sheet
                                break
                        
                        if target_sheet:
                            df = pd.read_excel(uploaded_file, sheet_name=target_sheet)
                        else:
                            df = pd.read_excel(uploaded_file, sheet_name=0)
                    except:
                        df = pd.read_excel(uploaded_file)
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                df_processed = process_samsa_data(df)
                
                save_samsa_data(df_processed, "ÙŠØ¯ÙˆÙŠ")
                st.session_state.show_upload = False
                st.success("âœ… ØªÙ… Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
                st.rerun()
                
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}")
    st.markdown('</div>', unsafe_allow_html=True)

if st.session_state.show_sla_upload:
    st.markdown('<div class="upload-area">', unsafe_allow_html=True)
    uploaded_sla = st.file_uploader(
        "Ø§Ø®ØªØ± Ù…Ù„Ù SLA Excel",
        type=['xlsx', 'xls'],
        key="sla_uploader"
    )
    
    if uploaded_sla:
        try:
            with st.spinner("Ù…Ø¹Ø§Ù„Ø¬Ø© SLA..."):
                # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªØ´Ø®ÙŠØµÙŠØ©
                sla_df = pd.read_excel(uploaded_sla)
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                sla_processed = process_sla_data(sla_df)
                
                if len(sla_processed) > 0:
                    save_sla_data(sla_processed, "ÙŠØ¯ÙˆÙŠ")
                    
                    # Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ SLA ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
                    if has_samsa_data():
                        saved_data = get_samsa_data()
                        df_current = saved_data['main_df']
                        df_updated = update_sla_calculations(df_current)
                        save_samsa_data(df_updated, "Ù…Ø­Ø¯Ø«_Ù…Ø¹_SLA")
                    
                    st.session_state.show_sla_upload = False
                    st.success("âœ… ØªÙ… Ø±ÙØ¹ Ù…Ù„Ù SLA ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª!")
                    st.rerun()
                else:
                    st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø© ÙÙŠ Ù…Ù„Ù SLA")
                    
        except Exception as e:
            st.error(f"Ø®Ø·Ø£: {str(e)}")
    st.markdown('</div>', unsafe_allow_html=True)

# Ø¨Ù‚ÙŠØ© Ø§Ù„ÙƒÙˆØ¯ ÙŠØªØ¨Ø¹ Ù†ÙØ³ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø£ØµÙ„ÙŠ
if has_samsa_data():
    saved_data = get_samsa_data()
    df = saved_data['main_df']
    
    # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    with st.expander("Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", expanded=False):
        display_columns = ['Ø±Ù‚Ù…_Ø§Ù„Ø´Ø­Ù†Ø©', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©', 'Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…']
        if has_sla_data():
            display_columns.extend(['SLA_Ø£ÙŠØ§Ù…', 'Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰'])
        
        available_display_columns = [col for col in display_columns if col in df.columns]
        st.dataframe(df[available_display_columns].head(10), use_container_width=True)
    
    # Ø§Ù„ÙÙ„Ø§ØªØ± - Ù…ÙØ­Ø³Ù†
    st.markdown("### ğŸ” Ø§Ù„ÙÙ„Ø§ØªØ±")
    filter_col1, filter_col2, filter_col3 = st.columns([3, 3, 6])
    
    with filter_col1:
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© Ù…Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù†Ø³Ø¯Ù„Ø©
        all_cities = []
        if 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©' in df.columns:
            all_cities = sorted([city for city in df['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'].dropna().unique() if str(city).strip()])
        
        if all_cities:
            selected_city = st.selectbox(
                "Ø§Ø®ØªØ± Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©:",
                ['Ø§Ù„ÙƒÙ„'] + all_cities,
                key="main_city_filter",
                help="Ø§Ø®ØªØ± Ù…Ø¯ÙŠÙ†Ø© Ù…Ø­Ø¯Ø¯Ø© Ù„Ù„ØªØµÙÙŠØ©"
            )
        else:
            selected_city = 'Ø§Ù„ÙƒÙ„'
            st.selectbox(
                "Ø§Ø®ØªØ± Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©:",
                ['Ø§Ù„ÙƒÙ„'],
                key="main_city_filter_empty",
                help="Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¯Ù† Ù…ØªØ§Ø­Ø©"
            )

    with filter_col2:
        countries = ['Ø§Ù„ÙƒÙ„']
        if 'Ø§Ù„Ø¯ÙˆÙ„Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©' in df.columns:
            countries += sorted([country for country in df['Ø§Ù„Ø¯ÙˆÙ„Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'].dropna().unique() if str(country).strip()])
        selected_country = st.selectbox("Ø§Ù„Ø¯ÙˆÙ„Ø©", countries, key="country_filter")
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„Ø§ØªØ±
    df_filtered = df.copy()
    
    if selected_city != 'Ø§Ù„ÙƒÙ„':
        df_filtered = df_filtered[df_filtered['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'] == selected_city]
    
    if selected_country != 'Ø§Ù„ÙƒÙ„' and 'Ø§Ù„Ø¯ÙˆÙ„Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©' in df.columns:
        df_filtered = df_filtered[df_filtered['Ø§Ù„Ø¯ÙˆÙ„Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'] == selected_country]
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
    total_all = len(df_filtered)
    excluded_shipments = len(df_filtered[df_filtered.get('Ù…Ø³ØªØ«Ù†Ù‰', False)])
    total_shipments = total_all - excluded_shipments
    
    # ÙÙ„ØªØ±Ø© Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø© Ù„Ù„Ø­Ø³Ø§Ø¨Ø§Øª
    df_active = df_filtered[~df_filtered.get('Ù…Ø³ØªØ«Ù†Ù‰', False)]
    
    delivered_shipments = len(df_active[df_active['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] == 'ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…']) if 'Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in df_active.columns else 0
    delivery_rate = (delivered_shipments / total_shipments * 100) if total_shipments > 0 else 0
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡
    performance_analysis = analyze_delivery_performance_fast(df_filtered)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¯Ù†
    cities_analysis = analyze_cities_performance_samsa(df_filtered)
    unique_cities = len(cities_analysis) if len(cities_analysis) > 0 else 0
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© - ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù…Ù„Ù SLA
    sla_compliant_shipments = 0
    fds_shipments = 0
    sla_rate = 0
    fds_rate = 0
    
    if has_sla_data() and 'Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰' in df_active.columns:
        # ÙÙ„ØªØ±Ø© Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„ØªÙŠ Ù„Ù‡Ø§ SLA Ù…Ø­Ø¯Ø¯ ÙÙ‚Ø·
        df_with_sla = df_active[df_active['SLA_Ø£ÙŠØ§Ù…'].notna()]
        total_sla_shipments = len(df_with_sla)
        
        if total_sla_shipments > 0:
            sla_compliant_shipments = len(df_with_sla[
                df_with_sla['Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰'].isin(['Ù‚Ø¨Ù„ SLA', 'ÙÙŠ SLA'])
            ])
            sla_rate = (sla_compliant_shipments / total_sla_shipments * 100)
            
            if 'ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©' in df_with_sla.columns:
                fds_shipments = len(df_with_sla[df_with_sla['ØªØ³Ù„ÙŠÙ…_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©'] == True])
                fds_rate = (fds_shipments / total_sla_shipments * 100)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø«Ø©
    sla_label = "SLA Ù†Ø³Ø¨Ø©" if has_sla_data() else "SLA ØºÙŠØ± Ù…ØªÙˆÙØ±"
    sla_delta_text = f"{sla_compliant_shipments:,}" if has_sla_data() else "Ø§Ø±ÙØ¹ Ù…Ù„Ù SLA"
    sla_delta_color = "#ff6fb3" if has_sla_data() else "#95a5a6"
    
    fds_label = "FDS - ØªØ³Ù„ÙŠÙ… Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¶Ù…Ù† SLA" if has_sla_data() else "FDS ØºÙŠØ± Ù…ØªÙˆÙØ±"
    fds_delta_text = f"{fds_shipments:,}" if has_sla_data() else "Ø§Ø±ÙØ¹ Ù…Ù„Ù SLA"
    fds_delta_color = "#f39c12" if has_sla_data() else "#95a5a6"
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø«Ø©
    st.markdown(f"""
    <div class="kpi-container">
        <div class="kpi-card shipments">
            <div class="kpi-value">{total_shipments:,}</div>
            <div class="kpi-label">Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©</div>
            <div class="kpi-delta" style="background: #e8e2ff; color: #5f27cd;">Samsa</div>
        </div>
        <div class="kpi-card delivered">
            <div class="kpi-value">{delivery_rate:.1f}%</div>
            <div class="kpi-label">DR - Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ³Ù„ÙŠÙ…</div>
            <div class="kpi-delta" style="background: #e0f9f9; color: #00a8a8;">{delivered_shipments:,}</div>
        </div>
        <div class="kpi-card transit">
            <div class="kpi-value">{sla_rate:.1f}%</div>
            <div class="kpi-label">{sla_label}</div>
            <div class="kpi-delta" style="background: #ffe0f3; color: {sla_delta_color};">{sla_delta_text}</div>
        </div>
        <div class="kpi-card cities">
            <div class="kpi-value">{fds_rate:.1f}%</div>
            <div class="kpi-label">{fds_label}</div>
            <div class="kpi-delta" style="background: #fef4e0; color: {fds_delta_color};">{fds_delta_text}</div>
        </div>
        <div class="kpi-card excluded">
            <div class="kpi-value">{excluded_shipments:,}</div>
            <div class="kpi-label">Ù…Ø³ØªØ«Ù†Ù‰</div>
            <div class="kpi-delta" style="background: #ffe0e0; color: #e74c3c;">Picked up</div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # --- Ø¬Ø¯ÙˆÙ„ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙŠØ¯ - ÙÙ‚Ø· Ø¥Ø°Ø§ ØªÙ… Ø±ÙØ¹ Ù…Ù„Ù SLA ---
    performance_metrics = calculate_performance_metrics(df_filtered)
    
    if len(performance_metrics) > 0 and has_sla_data():
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        st.markdown('<h3 class="chart-title">Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¯Ù† (Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨)</h3>', unsafe_allow_html=True)
        
        # ÙÙ„Ø§ØªØ± Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯
        perf_col1, perf_col2 = st.columns([3, 1])
        with perf_col1:
            search_perf_city = st.text_input("Ø§Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¯ÙŠÙ†Ø© (Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡)", key="search_perf_city")
        with perf_col2:
            num_rows_perf = st.selectbox(
                "Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ",
                [10, 25, 50, "Ø§Ù„ÙƒÙ„"],
                key="num_rows_perf"
            )
        
        filtered_perf = performance_metrics.copy()
        if search_perf_city:
            filtered_perf = filtered_perf[
                filtered_perf['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©'].str.contains(search_perf_city, case=False, na=False)
            ]
        
        if num_rows_perf != "Ø§Ù„ÙƒÙ„":
            display_perf = filtered_perf.head(num_rows_perf)
        else:
            display_perf = filtered_perf
        
        # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¬Ø¯ÙˆÙ„
        format_dict_perf = {
            'SLA_Ø§Ù„Ù…Ø­Ø¯Ø¯': '{:.0f} ÙŠÙˆÙ…',
            'SLA_Ù†Ø³Ø¨Ø©': '{:.1f}%',
            'DR': '{:.1f}%',
            'FDS': '{:.1f}%',
            'Pending': '{:.1f}%',
            'Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª': '{:,.0f}'
        }
        
        # Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ„ÙˆÙŠÙ†
        def color_performance_metric(val, good_threshold=80, bad_threshold=60):
            if pd.isna(val):
                return ''
            if val >= good_threshold:
                return 'background-color: #d4f4dd; color: #155724; font-weight: bold;'
            elif val <= bad_threshold:
                return 'background-color: #f8d7da; color: #721c24; font-weight: bold;'
            else:
                return 'background-color: #fff3cd; color: #856404; font-weight: bold;'
        
        def color_pending_metric(val, good_threshold=20, bad_threshold=40):
            if pd.isna(val):
                return ''
            if val <= good_threshold:
                return 'background-color: #d4f4dd; color: #155724; font-weight: bold;'
            elif val >= bad_threshold:
                return 'background-color: #f8d7da; color: #721c24; font-weight: bold;'
            else:
                return 'background-color: #fff3cd; color: #856404; font-weight: bold;'
        
        styled_perf = display_perf.style.format(format_dict_perf, na_rep='-')
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
        for col in ['SLA_Ù†Ø³Ø¨Ø©', 'DR', 'FDS']:
            if col in display_perf.columns:
                styled_perf = styled_perf.applymap(color_performance_metric, subset=[col])
        
        if 'Pending' in display_perf.columns:
            styled_perf = styled_perf.applymap(color_pending_metric, subset=['Pending'])
        
        st.dataframe(styled_perf, use_container_width=True, height=500)
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        csv_perf = display_perf.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ (CSV)",
            data=csv_perf,
            file_name=f"samsa_performance_metrics_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv"
        )
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Ø±Ø³Ø§Ù„Ø© Ø¹Ù†Ø¯Ù…Ø§ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù SLA
    if not has_sla_data():
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        st.markdown('<h3 class="chart-title">Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¯Ù†</h3>', unsafe_allow_html=True)
        st.warning("âš ï¸ **Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª SLA Ùˆ FDSØŒ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù SLA Ø£ÙˆÙ„Ø§Ù‹**")
        st.info("ğŸ“‹ Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± 'Ø±ÙØ¹ SLA' ÙÙŠ Ø§Ù„Ø£Ø¹Ù„Ù‰ Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¯Ù† ÙˆØ§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ù„ÙƒÙ„ Ù…Ø¯ÙŠÙ†Ø©")
        st.markdown('</div>', unsafe_allow_html=True)
    
    # --- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹ ---
    weekly_metrics = calculate_weekly_metrics(df_filtered)
    
    if len(weekly_metrics) > 0:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        st.markdown('<h3 class="chart-title">ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø­Ø³Ø¨ Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹</h3>', unsafe_allow_html=True)
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹
        st.markdown("#### ğŸ“Š Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠØ©")
        
        format_dict_weekly = {
            'SLA_Ù†Ø³Ø¨Ø©': '{:.1f}%',
            'DR': '{:.1f}%',
            'FDS': '{:.1f}%',
            'Pending': '{:.1f}%',
            'Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª': '{:,.0f}'
        }
        
        def color_performance_metric_weekly(val, good_threshold=80, bad_threshold=60):
            if pd.isna(val):
                return ''
            if val >= good_threshold:
                return 'background-color: #d4f4dd; color: #155724; font-weight: bold;'
            elif val <= bad_threshold:
                return 'background-color: #f8d7da; color: #721c24; font-weight: bold;'
            else:
                return 'background-color: #fff3cd; color: #856404; font-weight: bold;'
        
        def color_pending_metric_weekly(val, good_threshold=20, bad_threshold=40):
            if pd.isna(val):
                return ''
            if val <= good_threshold:
                return 'background-color: #d4f4dd; color: #155724; font-weight: bold;'
            elif val >= bad_threshold:
                return 'background-color: #f8d7da; color: #721c24; font-weight: bold;'
            else:
                return 'background-color: #fff3cd; color: #856404; font-weight: bold;'
        
        styled_weekly = weekly_metrics.style.format(format_dict_weekly, na_rep='-')
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ù„Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹
        for col in ['SLA_Ù†Ø³Ø¨Ø©', 'DR', 'FDS']:
            if col in weekly_metrics.columns:
                styled_weekly = styled_weekly.applymap(color_performance_metric_weekly, subset=[col])
        
        if 'Pending' in weekly_metrics.columns:
            styled_weekly = styled_weekly.applymap(color_pending_metric_weekly, subset=['Pending'])
        
        st.dataframe(styled_weekly, use_container_width=True, height=300)
        
        # Ù…Ø®Ø·Ø· Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹
        st.markdown("#### ğŸ“ˆ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ")
        
        fig_weekly_trend = go.Figure()
        
        # Ø¥Ø¶Ø§ÙØ© Ø®Ø·ÙˆØ· Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
        for metric, color in [('SLA_Ù†Ø³Ø¨Ø©', '#5f27cd'), ('DR', '#00d2d3'), ('FDS', '#ff9ff3'), ('Pending', '#ee5a6f')]:
            if metric in weekly_metrics.columns:
                fig_weekly_trend.add_trace(go.Scatter(
                    x=weekly_metrics['Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹'],
                    y=weekly_metrics[metric],
                    mode='lines+markers',
                    name=metric,
                    line=dict(color=color, width=3),
                    marker=dict(size=8)
                ))
        
        fig_weekly_trend.update_layout(
            title='Ø§ØªØ¬Ø§Ù‡ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¹Ø¨Ø± Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹',
            xaxis_title='Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹',
            yaxis_title='Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© (%)',
            height=400,
            font=dict(family='Cairo', size=12),
            hovermode='x unified'
        )
        
        st.plotly_chart(fig_weekly_trend, use_container_width=True)
        
        # ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹
        csv_weekly = weekly_metrics.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠØ© (CSV)",
            data=csv_weekly,
            file_name=f"samsa_weekly_metrics_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv"
        )
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # --- Ù‚Ø³Ù… ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„ÙØ±Ø¯ÙŠØ© Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ---
    st.markdown('<div class="chart-container">', unsafe_allow_html=True)
    st.markdown('<h3 class="chart-title">ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„ÙØ±Ø¯ÙŠØ© (Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨)</h3>', unsafe_allow_html=True)
    
    # ÙÙ„Ø§ØªØ± Ù‚Ø³Ù… Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„ÙØ±Ø¯ÙŠØ©
    detail_col1, detail_col2, detail_col3 = st.columns(3)
    
    with detail_col1:
        status_filter = st.selectbox(
            "ÙÙ„ØªØ± Ø§Ù„Ø­Ø§Ù„Ø©",
            ["Ø§Ù„ÙƒÙ„", "ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…", "Ù‚ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠÙ„", "Ù…Ø±ØªØ¬Ø¹"],
            key="status_filter_detail"
        )
    
    with detail_col2:
        sla_filter = st.selectbox(
            "ÙÙ„ØªØ± SLA",
            ["Ø§Ù„ÙƒÙ„", "Ù‚Ø¨Ù„ SLA", "ÙÙŠ SLA", "Ø¨Ø¹Ø¯ SLA", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"],
            key="sla_filter_detail"
        )
    
    with detail_col3:
        num_rows_detail = st.selectbox(
            "Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ",
            [50, 100, 200, 500, "Ø§Ù„ÙƒÙ„"],
            key="num_rows_detail"
        )
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„Ø§ØªØ±
    detail_df = df_active.copy()
    
    if status_filter != "Ø§Ù„ÙƒÙ„":
        detail_df = detail_df[detail_df['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] == status_filter]
    
    if sla_filter != "Ø§Ù„ÙƒÙ„" and 'Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰' in detail_df.columns:
        detail_df = detail_df[detail_df['Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰'] == sla_filter]
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…
    if 'ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…' in detail_df.columns:
        detail_df = detail_df.sort_values('ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…', ascending=False)
    
    # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ù„Ù„Ø¹Ø±Ø¶
    if num_rows_detail != "Ø§Ù„ÙƒÙ„":
        display_detail_df = detail_df.head(num_rows_detail)
    else:
        display_detail_df = detail_df
    
    if len(display_detail_df) > 0:
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
        final_report_columns = [
            'Ø±Ù‚Ù…_Ø§Ù„Ø´Ø­Ù†Ø©', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©', 'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©', 
            'Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰', 'Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…',
            'ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…', 'ØªØ§Ø±ÙŠØ®_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©', 'ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªØ³Ù„ÙŠÙ…',
            'Ø±Ù‚Ù…_Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹'
        ]
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªÙˆÙØ±Ø©
        additional_columns = [
            'Ø§Ø³Ù…_Ø§Ù„Ù…Ø±Ø³Ù„', 'Ø§Ø³Ù…_Ø§Ù„Ù…Ø³ØªÙ„Ù…', 'Ù‡Ø§ØªÙ_Ø§Ù„Ù…Ø³ØªÙ„Ù…', 
            'Ø¹Ù†ÙˆØ§Ù†_Ø§Ù„Ù…Ø³ØªÙ„Ù…', 'Ø§Ù„Ù…Ø¨Ù„Øº_Ø§Ù„Ù…Ø³ØªØ­Ù‚', 'Ø¹Ø¯Ø¯_Ø§Ù„Ù‚Ø·Ø¹', 
            'Ø§Ù„ÙˆØ²Ù†', 'Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª'
        ]
        
        for col in additional_columns:
            if col in display_detail_df.columns:
                final_report_columns.append(col)
        
        # ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
        available_columns = [col for col in final_report_columns if col in display_detail_df.columns]
        final_display_df = display_detail_df[available_columns].copy()
        
        st.markdown(f"### ğŸ“‹ Ø¹Ø±Ø¶ {len(final_display_df):,} Ø´Ø­Ù†Ø©")
        
        # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¹Ø±Ø¶
        format_dict_detail = {}
        if 'Ø§Ù„Ù…Ø¨Ù„Øº_Ø§Ù„Ù…Ø³ØªØ­Ù‚' in final_display_df.columns:
            format_dict_detail['Ø§Ù„Ù…Ø¨Ù„Øº_Ø§Ù„Ù…Ø³ØªØ­Ù‚'] = '{:.2f}'
        if 'Ø§Ù„ÙˆØ²Ù†' in final_display_df.columns:
            format_dict_detail['Ø§Ù„ÙˆØ²Ù†'] = '{:.2f}'
        if 'Ø¹Ø¯Ø¯_Ø§Ù„Ù‚Ø·Ø¹' in final_display_df.columns:
            format_dict_detail['Ø¹Ø¯Ø¯_Ø§Ù„Ù‚Ø·Ø¹'] = '{:.0f}'
        
        # Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ„ÙˆÙŠÙ† Ù„Ù„Ø­Ø§Ù„Ø© SLA
        def style_sla_status_detail(val):
            if val == 'Ù‚Ø¨Ù„ SLA':
                return 'background-color: #d4edda; color: #155724; font-weight: bold;'
            elif val == 'ÙÙŠ SLA':
                return 'background-color: #d1ecf1; color: #0c5460; font-weight: bold;'
            elif val == 'Ø¨Ø¹Ø¯ SLA':
                return 'background-color: #f8d7da; color: #721c24; font-weight: bold;'
            else:
                return 'background-color: #f8f9fa; color: #6c757d;'
        
        # Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ„ÙˆÙŠÙ† Ù„Ø­Ø§Ù„Ø© Ø§Ù„ØªØ³Ù„ÙŠÙ…
        def style_delivery_status(val):
            if val == 'ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…':
                return 'background-color: #d4edda; color: #155724; font-weight: bold;'
            elif val == 'Ù‚ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠÙ„':
                return 'background-color: #fff3cd; color: #856404; font-weight: bold;'
            elif val == 'Ù…Ø±ØªØ¬Ø¹':
                return 'background-color: #f8d7da; color: #721c24; font-weight: bold;'
            else:
                return ''
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
        styled_detail_df = final_display_df.style.format(format_dict_detail, na_rep='-')
        
        if 'Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰' in final_display_df.columns:
            styled_detail_df = styled_detail_df.applymap(
                style_sla_status_detail, 
                subset=['Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰']
            )
        
        if 'Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in final_display_df.columns:
            styled_detail_df = styled_detail_df.applymap(
                style_delivery_status, 
                subset=['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…']
            )
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„
        st.dataframe(styled_detail_df, use_container_width=True, height=600)
        
        # Ø²Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù„Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        csv_final = final_display_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (CSV)",
            data=csv_final,
            file_name=f"samsa_final_report_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv",
            help="Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„ Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„ ÙˆØ§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"
        )
    else:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø´Ø­Ù†Ø§Øª ØªØ·Ø§Ø¨Ù‚ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©")
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ø§Ù„Ø£ØµÙ„ÙŠØ©
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        st.markdown('<h3 class="chart-title">Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø­Ù†Ø§Øª</h3>', unsafe_allow_html=True)
        
        if 'Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in df_active.columns:
            status_counts = df_active['Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'].value_counts()
            
            main_statuses = ['ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…', 'Ù‚ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠÙ„', 'Ù…Ø±ØªØ¬Ø¹']
            for status in main_statuses:
                if status not in status_counts.index:
                    status_counts[status] = 0
            
            status_counts = status_counts.reindex(main_statuses, fill_value=0)
            status_counts = status_counts[status_counts > 0]
            
            fig_status = px.pie(
                values=status_counts.values,
                names=status_counts.index,
                color_discrete_map={
                    'ØªÙ… Ø§Ù„ØªØ³Ù„ÙŠÙ…': '#00d2d3',
                    'Ù‚ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠÙ„': '#ff9ff3',
                    'Ù…Ø±ØªØ¬Ø¹': '#ee5a6f'
                },
                hole=0.4
            )
            
            fig_status.update_traces(
                textposition='inside',
                textinfo='percent+label',
                textfont_size=12,
                marker=dict(line=dict(color='#FFFFFF', width=2)),
                texttemplate='%{label}<br>%{percent}'
            )
            
            fig_status.update_layout(
                height=350,
                font=dict(family="Cairo", size=12),
                showlegend=False,
                margin=dict(t=20, b=20, l=20, r=20)
            )
            
            st.plotly_chart(fig_status, use_container_width=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        st.markdown('<h3 class="chart-title">ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø­Ø³Ø¨ SLA</h3>', unsafe_allow_html=True)
        
        if 'Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰' in df_active.columns:
            sla_attempt_counts = df_active['Ø­Ø§Ù„Ø©_SLA_Ù…Ø­Ø§ÙˆÙ„Ø©_Ø£ÙˆÙ„Ù‰'].value_counts()
            
            fig_sla_attempts = go.Figure()
            
            colors = {'Ù‚Ø¨Ù„ SLA': '#00d2d3', 'ÙÙŠ SLA': '#5f27cd', 'Ø¨Ø¹Ø¯ SLA': '#ee5a6f', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯': '#95a5a6'}
            
            for i, (category, count) in enumerate(sla_attempt_counts.items()):
                percentage = (count / len(df_active) * 100)
                fig_sla_attempts.add_trace(go.Bar(
                    x=[category],
                    y=[count],
                    text=[f'{count} ({percentage:.1f}%)'],
                    textposition='outside',
                    marker_color=colors.get(category, '#95a5a6'),
                    showlegend=False,
                    textfont=dict(size=12, color='#2D3748')
                ))
            
            fig_sla_attempts.update_layout(
                height=350,
                font=dict(family="Cairo", size=12),
                xaxis_title="Ø­Ø§Ù„Ø© SLA",
                yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø­Ù†Ø§Øª",
                showlegend=False,
                margin=dict(t=30, b=50, l=50, r=20),
                bargap=0.2,
                plot_bgcolor='white',
                yaxis=dict(gridcolor='#E2E8F0', gridwidth=1)
            )
            
            st.plotly_chart(fig_sla_attempts, use_container_width=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¯Ù† Ø§Ù„Ø£ØµÙ„ÙŠ
    if len(cities_analysis) > 0:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        st.markdown('<h3 class="chart-title">Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ù† (Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ)</h3>', unsafe_allow_html=True)
        
        # ÙÙ„Ø§ØªØ± Ø¬Ø¯ÙˆÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ù†
        city_table_col1, city_table_col2 = st.columns([3,1])
        with city_table_col1:
            search_city_table = st.text_input("Ø§Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¯ÙŠÙ†Ø© (Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ù†)", key="search_city_table")
        with city_table_col2:
            num_rows_cities = st.selectbox(
                "Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ",
                [10, 25, 50, "Ø§Ù„ÙƒÙ„"],
                key="num_rows_cities"
            )
        
        filtered_cities_analysis = cities_analysis.copy()
        if search_city_table:
            filtered_cities_analysis = filtered_cities_analysis[
                filtered_cities_analysis.index.str.contains(search_city_table, case=False, na=False)
            ]
        
        if num_rows_cities != "Ø§Ù„ÙƒÙ„":
            display_cities_table = filtered_cities_analysis.head(num_rows_cities).reset_index()
        else:
            display_cities_table = filtered_cities_analysis.reset_index()
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„Ø¹Ø±Ø¶
        display_columns = ['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©', 'Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª']
        format_dict = {}
        
        if 'Ù†Ø³Ø¨Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in display_cities_table.columns:
            display_columns.append('Ù†Ø³Ø¨Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…')
            format_dict['Ù†Ø³Ø¨Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'] = '{:.1f}%'
        
        if 'Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ù„Ù„ØªÙˆØµÙŠÙ„' in display_cities_table.columns:
            display_columns.append('Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ù„Ù„ØªÙˆØµÙŠÙ„')
            format_dict['Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ù„Ù„ØªÙˆØµÙŠÙ„'] = '{:.1f}'
        
        if 'Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰' in display_cities_table.columns:
            display_columns.append('Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰')
            format_dict['Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'] = '{:.1f}'
        
        # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¬Ø¯ÙˆÙ„
        styled_df = display_cities_table[display_columns].style.format(format_dict, na_rep='-')
        
        if 'Ù†Ø³Ø¨Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…' in display_columns:
            styled_df = styled_df.background_gradient(
                subset=['Ù†Ø³Ø¨Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'],
                cmap='Greens',
                vmin=70,
                vmax=100
            ).set_properties(**{'font-weight': 'bold'}, subset=['Ù†Ø³Ø¨Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'])
        
        if 'Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ù„Ù„ØªÙˆØµÙŠÙ„' in display_columns:
             styled_df = styled_df.background_gradient(
                subset=['Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ù„Ù„ØªÙˆØµÙŠÙ„'],
                cmap='Reds_r',
                vmin=0,
                vmax=5
            ).set_properties(**{'font-weight': 'bold'}, subset=['Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ù„Ù„ØªÙˆØµÙŠÙ„'])
        
        if 'Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰' in display_columns:
             styled_df = styled_df.background_gradient(
                subset=['Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'],
                cmap='Reds_r',
                vmin=0,
                vmax=5
            ).set_properties(**{'font-weight': 'bold'}, subset=['Ù…ØªÙˆØ³Ø·_Ø£ÙŠØ§Ù…_Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©_Ø§Ù„Ø£ÙˆÙ„Ù‰'])

        st.dataframe(styled_df, use_container_width=True, height=400)
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # --- Ù‚Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© ---
    if has_samsa_data():
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        st.markdown('<h3 class="chart-title">ğŸ” Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ SLA</h3>', unsafe_allow_html=True)
        
        # ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
        if has_sla_data():
            sla_info = get_sla_data()
            sla_df = sla_info['sla_df']
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù…Ø¯Ù† Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ SLA
            sla_cities = set(sla_df['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©'].str.strip().str.upper())
            
            # ÙØ­Øµ Ø§Ù„Ù…Ø¯Ù† ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            if 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©' in df.columns:
                # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
                df_unmatched = df[df['SLA_Ø£ÙŠØ§Ù…'].isna() & df['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'].notna()].copy()
                
                if len(df_unmatched) > 0:
                    st.error(f"âŒ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(df_unmatched):,} Ø´Ø­Ù†Ø© ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ù…Ù„Ù SLA")
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¯Ù† ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
                    unmatched_cities = df_unmatched['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'].value_counts()
                    
                    st.markdown("### ğŸ“‹ Ø§Ù„Ù…Ø¯Ù† ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©:")
                    
                    # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¯Ù† ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
                    unmatched_summary = pd.DataFrame({
                        'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©': unmatched_cities.index,
                        'Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª': unmatched_cities.values,
                        'Ø§Ù„Ù†Ø³Ø¨Ø©': (unmatched_cities.values / len(df_unmatched) * 100).round(1)
                    })
                    
                    # ØªÙ†Ø³ÙŠÙ‚ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø¯Ù† ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
                    st.dataframe(
                        unmatched_summary.style.format({
                            'Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª': '{:,.0f}',
                            'Ø§Ù„Ù†Ø³Ø¨Ø©': '{:.1f}%'
                        }).background_gradient(subset=['Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª'], cmap='Reds'),
                        use_container_width=True,
                        height=200
                    )
                    
                    # ÙÙ„Ø§ØªØ± Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
                    st.markdown("### ğŸ” ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø´Ø­Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©:")
                    
                    unmatched_col1, unmatched_col2 = st.columns([2, 1])
                    
                    with unmatched_col1:
                        selected_unmatched_city = st.selectbox(
                            "Ø§Ø®ØªØ± Ù…Ø¯ÙŠÙ†Ø© ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚Ø©:",
                            ['Ø§Ù„ÙƒÙ„'] + list(unmatched_cities.index),
                            key="unmatched_city_filter"
                        )
                    
                    with unmatched_col2:
                        unmatched_rows_count = st.selectbox(
                            "Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ:",
                            [10, 25, 50, "Ø§Ù„ÙƒÙ„"],
                            key="unmatched_rows_count"
                        )
                    
                    # ØªØ·Ø¨ÙŠÙ‚ ÙÙ„ØªØ± Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©
                    display_unmatched = df_unmatched.copy()
                    if selected_unmatched_city != 'Ø§Ù„ÙƒÙ„':
                        display_unmatched = display_unmatched[
                            display_unmatched['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'] == selected_unmatched_city
                        ]
                    
                    # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ
                    if unmatched_rows_count != "Ø§Ù„ÙƒÙ„":
                        display_unmatched = display_unmatched.head(unmatched_rows_count)
                    
                    # Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„Ø¹Ø±Ø¶
                    unmatched_display_columns = [
                        'Ø±Ù‚Ù…_Ø§Ù„Ø´Ø­Ù†Ø©', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©', 'Ø­Ø§Ù„Ø©_Ø§Ù„ØªØ³Ù„ÙŠÙ…'
                    ]
                    
                    # Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ø¥Ù† ÙˆØ¬Ø¯Øª
                    additional_unmatched_columns = [
                        'Ø§Ø³Ù…_Ø§Ù„Ù…Ø³ØªÙ„Ù…', 'Ù‡Ø§ØªÙ_Ø§Ù„Ù…Ø³ØªÙ„Ù…', 'Ø¹Ù†ÙˆØ§Ù†_Ø§Ù„Ù…Ø³ØªÙ„Ù…', 
                        'ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…', 'ØªØ§Ø±ÙŠØ®_Ø£ÙˆÙ„_Ù…Ø­Ø§ÙˆÙ„Ø©', 'ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªØ³Ù„ÙŠÙ…',
                        'Ø§Ù„Ù…Ø¨Ù„Øº_Ø§Ù„Ù…Ø³ØªØ­Ù‚', 'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'
                    ]
                    
                    for col in additional_unmatched_columns:
                        if col in display_unmatched.columns:
                            unmatched_display_columns.append(col)
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                    if len(display_unmatched) > 0:
                        st.markdown(f"**Ø¹Ø±Ø¶ {len(display_unmatched):,} Ø´Ø­Ù†Ø© ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚Ø©:**")
                        
                        # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                        unmatched_styled = display_unmatched[unmatched_display_columns].style.applymap(
                            lambda x: 'background-color: #ffebee; color: #c62828; font-weight: bold;',
                            subset=['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©']
                        )
                        
                        st.dataframe(unmatched_styled, use_container_width=True, height=400)
                        
                        # Ø£Ø²Ø±Ø§Ø± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª
                        action_col1, action_col2, action_col3 = st.columns(3)
                        
                        with action_col1:
                            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
                            csv_unmatched = display_unmatched[unmatched_display_columns].to_csv(
                                index=False, encoding='utf-8-sig'
                            )
                            st.download_button(
                                label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©",
                                data=csv_unmatched,
                                file_name=f"unmatched_shipments_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                                mime="text/csv",
                                help="ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø­Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©"
                            )
                        
                        with action_col2:
                            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù SLA Ù„Ù„Ù…Ø¯Ù† Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
                            if st.button("ğŸ“‹ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù SLA Ù„Ù„Ù…Ø¯Ù† Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©", key="create_missing_sla"):
                                missing_cities_sla = pd.DataFrame({
                                    'City Name': unmatched_cities.index,
                                    'Region': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',  # ÙŠÙ…ÙƒÙ† ØªØ®ØµÙŠØµÙ‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹
                                    'SLA': 2  # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                                })
                                
                                csv_missing_sla = missing_cities_sla.to_csv(index=False, encoding='utf-8-sig')
                                st.download_button(
                                    label="ğŸ’¾ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù SLA Ù„Ù„Ù…Ø¯Ù† Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©",
                                    data=csv_missing_sla,
                                    file_name=f"missing_cities_sla_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                                    mime="text/csv",
                                    help="Ù…Ù„Ù SLA Ø¬Ø§Ù‡Ø² Ù„Ù„Ù…Ø¯Ù† Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©"
                                )
                        
                        with action_col3:
                            # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©
                            st.metric(
                                "Ø¥Ø¬Ù…Ø§Ù„ÙŠ ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚",
                                f"{len(df_unmatched):,}",
                                delta=f"{len(df_unmatched)/len(df)*100:.1f}% Ù…Ù† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹"
                            )
                    
                    # Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„Ø­Ù„
                    st.markdown("### ğŸ’¡ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„Ø­Ù„:")
                    
                    suggestions_col1, suggestions_col2 = st.columns(2)
                    
                    with suggestions_col1:
                        st.info("""
                        **Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø­Ù„:**
                        1. Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¯Ù† Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ù„Ù…Ù„Ù SLA Ø§Ù„Ø­Ø§Ù„ÙŠ
                        2. ØªØ­Ø¯ÙŠØ« Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø¯Ù† ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
                        3. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù„Ù SLA Ø§Ù„Ù…ÙÙ†Ø´Ø£ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
                        """)
                    
                    with suggestions_col2:
                        st.warning("""
                        **ØªØ£Ø«ÙŠØ± Ø¹Ø¯Ù… Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©:**
                        - Ø¹Ø¯Ù… Ø§Ø­ØªØ³Ø§Ø¨ Ù‡Ø°Ù‡ Ø§Ù„Ø´Ø­Ù†Ø§Øª ÙÙŠ Ù…Ø¤Ø´Ø±Ø§Øª SLA
                        - Ù†Ù‚Øµ ÙÙŠ Ø¯Ù‚Ø© Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
                        - ØªØ£Ø«ÙŠØ± Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨Ø§Øª FDS
                        """)
                    
                    # ÙØ­Øµ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ ÙÙŠ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø¯Ù†
                    st.markdown("### ğŸ” ÙØ­Øµ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù…Ø¹ Ø§Ù„Ù…Ø¯Ù† Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©:")
                    
                    similar_matches = []
                    for unmatched_city in unmatched_cities.index[:5]:  # Ø£ÙˆÙ„ 5 Ù…Ø¯Ù†
                        unmatched_upper = unmatched_city.upper().strip()
                        for sla_city in sla_df['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©']:
                            sla_upper = str(sla_city).upper().strip()
                            if unmatched_upper in sla_upper or sla_upper in unmatched_upper:
                                if unmatched_city != sla_city:
                                    similar_matches.append({
                                        'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_ØºÙŠØ±_Ù…Ø·Ø§Ø¨Ù‚Ø©': unmatched_city,
                                        'Ù…Ø¯ÙŠÙ†Ø©_Ù…Ø´Ø§Ø¨Ù‡Ø©_ÙÙŠ_SLA': sla_city,
                                        'Ø¹Ø¯Ø¯_Ø§Ù„Ø´Ø­Ù†Ø§Øª': unmatched_cities[unmatched_city]
                                    })
                    
                    if similar_matches:
                        st.markdown("**Ù…Ø¯Ù† Ù‚Ø¯ ØªÙƒÙˆÙ† Ù…ØªØ´Ø§Ø¨Ù‡Ø©:**")
                        similar_df = pd.DataFrame(similar_matches)
                        st.dataframe(similar_df, use_container_width=True, height=200)
                        st.info("ğŸ’¡ Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ù„ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¯Ù†")
                    
                else:
                    st.success("âœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ù…Ù„Ù SLA!")
                    
                    # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
                    total_with_cities = len(df[df['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©'].notna()])
                    matched_count = len(df[df['SLA_Ø£ÙŠØ§Ù…'].notna()])
                    match_rate = (matched_count / total_with_cities * 100) if total_with_cities > 0 else 0
                    
                    st.metric(
                        "Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©",
                        f"{match_rate:.1f}%",
                        delta=f"{matched_count:,} Ù…Ù† {total_with_cities:,}"
                    )
            else:
                st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©_Ø§Ù„ÙˆØ¬Ù‡Ø©' ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        else:
            st.info("ğŸ“‹ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù SLA Ø£ÙˆÙ„Ø§Ù‹ Ù„ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©")
            
        st.markdown('</div>', unsafe_allow_html=True)

else:
    st.info("ğŸ‘† Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ 'Ø±ÙØ¹ Samsa' Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„")

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ø§Ù„Ù…Ø­Ø¯Ø«
add_logout_button()
with st.sidebar:
    st.markdown("### ğŸ“Š Ø§Ù„Ø­Ø§Ù„Ø©")
    
    if has_samsa_data():
        saved_info = get_samsa_data()
        total_rows = saved_info['total_rows']
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ«Ù†Ø§Ø©
        df = saved_info['main_df']
        excluded_count = len(df[df.get('Ù…Ø³ØªØ«Ù†Ù‰', False)])
        active_count = total_rows - excluded_count
        
        st.success(f"âœ“ {total_rows:,} Ø´Ø­Ù†Ø© Ù…Ø­Ù…Ù„Ø©")
        st.info(f"ğŸ“¦ {active_count:,} Ø´Ø­Ù†Ø© Ù†Ø´Ø·Ø©")
        st.warning(f"ğŸš« {excluded_count:,} Ù…Ø³ØªØ«Ù†Ø§Ø©")
        
        if has_sla_data():
            sla_info = get_sla_data()
            st.success(f"ğŸ“‹ {sla_info['total_cities']} Ù…Ø¯ÙŠÙ†Ø© SLA")
            
            # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
            if 'SLA_Ø£ÙŠØ§Ù…' in df.columns:
                sla_matches = df['SLA_Ø£ÙŠØ§Ù…'].notna().sum()
                sla_match_rate = (sla_matches / len(df)) * 100
                st.info(f"ğŸ¯ Ù…Ø·Ø§Ø¨Ù‚Ø©: {sla_match_rate:.1f}%")
        else:
            st.warning("ğŸ“‹ Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ù…Ù„Ù SLA")
            st.info("Ø§Ø¶ØºØ· 'Ø±ÙØ¹ SLA' Ù„ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª")
    else:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª")
    
    st.markdown("---")
    st.markdown("### âš¡ Ø§Ù„Ø¥ØµÙ„Ø§Ø­Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©")
    st.success("âœ… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©")
    st.success("âœ… Ø±Ø¨Ø· ØµØ­ÙŠØ­ Ù…Ø¹ Ù…Ù„Ù SLA")
    st.success("âœ… Ø­Ø³Ø§Ø¨ Ø¯Ù‚ÙŠÙ‚ Ù„Ù„Ù…Ø¤Ø´Ø±Ø§Øª")
    st.success("âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©")
    st.success("âœ… Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„ØµØ­ÙŠØ­")
    st.info("ğŸ“Š ØªØ·Ø§Ø¨Ù‚ ØªØ§Ù… Ù…Ø¹ Ù…Ù„ÙÙƒ Ø§Ù„Ø­Ø§Ù„ÙŠ")

# Ø§Ù„ØªØ°ÙŠÙŠÙ„ Ø§Ù„Ù…Ø¨Ø³Ø·
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #999; font-size: 0.8rem;">
    Samsa Analytics - Ù…ÙØµØ­Ø­ ÙˆØ¬Ø§Ù‡Ø² Ù„Ù„Ø¹Ù…Ù„ Ù…Ø¹ Ù…Ù„ÙØ§ØªÙƒ Ø§Ù„Ø­Ø§Ù„ÙŠØ© - Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ÙŠØ§Ù… Ù…ÙØ­Ø¯Ø«
</div>
""", unsafe_allow_html=True)
